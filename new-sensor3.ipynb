{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"dataset/cleaned\"\n",
    "sensor_name = \"Sensor 3\"\n",
    "save_folder = f\"saved_model/{sensor_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\n",
    "    f\"{dataset_folder}/train/{sensor_name}_train.csv\"\n",
    ")\n",
    "val_data = pd.read_csv(\n",
    "    f\"{dataset_folder}/val/{sensor_name}_val.csv\"\n",
    ")\n",
    "test_data = pd.read_csv(\n",
    "    f\"{dataset_folder}/test/{sensor_name}_test.csv\"\n",
    ")\n",
    "\n",
    "train_data[\"created_at\"] = pd.to_datetime(train_data[\"created_at\"], format=\"ISO8601\")\n",
    "val_data[\"created_at\"] = pd.to_datetime(val_data[\"created_at\"], format=\"ISO8601\")\n",
    "test_data[\"created_at\"] = pd.to_datetime(test_data[\"created_at\"], format=\"ISO8601\")\n",
    "\n",
    "train_data.set_index(\"created_at\", inplace=True)\n",
    "val_data.set_index(\"created_at\", inplace=True)\n",
    "test_data.set_index(\"created_at\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[['power']]\n",
    "val_data = val_data[['power']]\n",
    "test_data = test_data[['power']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "val_data_scaled = scaler.transform(val_data)\n",
    "test_data_scaled = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, time_steps=24):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        X.append(data[i:i + time_steps])\n",
    "        y.append(data[i + time_steps])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_sequences(train_data_scaled, time_steps=24)\n",
    "X_val, y_val = create_sequences(val_data_scaled, time_steps=24)\n",
    "X_test, y_test = create_sequences(test_data_scaled, time_steps=24)\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model with modifications\n",
    "model = Sequential()\n",
    "\n",
    "# Bidirectional LSTM Layer\n",
    "model.add(Bidirectional(LSTM(128, activation='relu', return_sequences=True, kernel_regularizer=l2(0.01), input_shape=(X_train.shape[1], 1))))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Additional LSTM Layer\n",
    "model.add(LSTM(64, activation='relu', return_sequences=True, kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Final LSTM Layer\n",
    "model.add(LSTM(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model with learning rate scheduler\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate=1e-3, decay_steps=1000, decay_rate=0.9)\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=32, batch_size=64, validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rescaled = scaler.inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "mae = mean_absolute_error(y_test_rescaled, y_pred_rescaled)\n",
    "mse = mean_squared_error(y_test_rescaled, y_pred_rescaled)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test_rescaled, y_pred_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance Metrics:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"RÂ² Score: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test_rescaled, label='True Power', color='blue', alpha=0.8)\n",
    "plt.plot(y_pred_rescaled, label='Predicted Power', color='orange', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.title(\"Power Consumption Forecast\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Power (Watt)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test_rescaled - y_pred_rescaled\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title('Residuals Distribution')\n",
    "plt.xlabel('Error (Watt)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({\n",
    "    'time': test_data.index[24:].strftime('%Y-%m-%dT%H:%M:%S'),\n",
    "    'predicted_power': y_pred_rescaled.flatten(),\n",
    "    'actual_power': y_test_rescaled.flatten(),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['time'] = pd.to_datetime(result_df['time'], format=\"ISO8601\")\n",
    "result_df['date'] = result_df['time'].dt.date\n",
    "daily_counts = result_df.groupby(['date']).size().reset_index(name='count')\n",
    "daily_counts[\"date\"] = daily_counts[\"date\"].astype(str)\n",
    "\n",
    "dates = []\n",
    "predicted_energy = []\n",
    "actual_energy = []\n",
    "different = []\n",
    "\n",
    "for _, row in daily_counts.iterrows():\n",
    "    date = row[\"date\"]\n",
    "    \n",
    "    sensor_data = result_df[result_df[\"date\"] == pd.to_datetime(date).date()]\n",
    "    sensor_data = sensor_data.sort_values(by=\"time\")\n",
    "    \n",
    "    sensor_data[\"time_diff\"] = sensor_data[\"time\"].diff().dt.total_seconds()\n",
    "    average_interval = sensor_data[\"time_diff\"].mean()\n",
    "    \n",
    "    total_energy_predicted = 0\n",
    "    total_energy_actual = 0\n",
    "    for _, row in sensor_data.iterrows():\n",
    "        predicted_power = row[\"predicted_power\"]\n",
    "        actual_power = row[\"actual_power\"]\n",
    "        interval = average_interval / 3600\n",
    "\n",
    "        predicted_energy_value = (predicted_power * interval) / 1000\n",
    "        total_energy_predicted += predicted_energy_value\n",
    "\n",
    "        actual_energy_value = (actual_power * interval) / 1000\n",
    "        total_energy_actual += actual_energy_value\n",
    "\n",
    "    dates.append(date)\n",
    "    predicted_energy.append(total_energy_predicted)\n",
    "    actual_energy.append(total_energy_actual)\n",
    "    different.append(total_energy_actual - total_energy_predicted)\n",
    "\n",
    "    print(f\"Different energy consumption ({date}):\", total_energy_actual - total_energy_predicted, \"kWh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(dates, predicted_energy, label=\"Predicted Energy (kWh)\", marker='o', linestyle='-', color='blue')\n",
    "plt.plot(dates, actual_energy, label=\"Actual Energy (kWh)\", marker='o', linestyle='-', color='red')\n",
    "plt.title(\"Predicted vs Actual Energy Consumption per Day\", fontsize=14)\n",
    "plt.xlabel(\"Date\", fontsize=12)\n",
    "plt.ylabel(\"Energy (kWh)\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(dates, different, label=\"Different Energy (kWh)\", marker='o', linestyle='-', color='blue')\n",
    "plt.title(\"Different Predicted vs Actual Energy Consumption per Day\", fontsize=14)\n",
    "plt.xlabel(\"Date\", fontsize=12)\n",
    "plt.ylabel(\"Energy (kWh)\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
