{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_date_from = \"2024-05-18\"\n",
    "train_date_to = \"2024-06-30\"\n",
    "\n",
    "val_date_from = \"2024-07-01\"\n",
    "val_date_to = \"2024-07-21\"\n",
    "\n",
    "test_date_from = \"2024-11-10\"\n",
    "test_date_to = \"2024-11-21\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_file = \"dataset/new_dataset.csv\"\n",
    "setup_folder = \"dataset/setup\"\n",
    "cleaned_folder = \"dataset/cleaned\"\n",
    "cleaned_train_folder = f\"{cleaned_folder}/train\"\n",
    "cleaned_val_folder = f\"{cleaned_folder}/val\"\n",
    "cleaned_test_folder = f\"{cleaned_folder}/test\"\n",
    "cleaned_test_per_day_folder = f\"{cleaned_folder}/test_per_day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(setup_folder, exist_ok=True)\n",
    "os.makedirs(cleaned_folder, exist_ok=True)\n",
    "os.makedirs(cleaned_train_folder, exist_ok=True)\n",
    "os.makedirs(cleaned_val_folder, exist_ok=True)\n",
    "os.makedirs(cleaned_test_folder, exist_ok=True)\n",
    "os.makedirs(cleaned_test_per_day_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Columns Index(['id', 'created_at', 'updated_at', 'deleted_at', 'name', 'voltage',\n",
      "       'current', 'power', 'power_factor', 'frequency', 'energy',\n",
      "       'apparent_power', 'reactive_power', 'date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "base_dataset = pd.read_csv(base_file)\n",
    "base_dataset[\"created_at\"] = pd.to_datetime(\n",
    "    base_dataset[\"created_at\"], format=\"ISO8601\", utc=True\n",
    ")\n",
    "\n",
    "base_dataset = base_dataset.sort_values(by=[\"created_at\", \"name\"])\n",
    "base_dataset[\"date\"] = base_dataset[\"created_at\"].dt.date\n",
    "\n",
    "print(\"Dataset Columns\", base_dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(data, path):\n",
    "    with open(path, \"w\") as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "    print(f\"Files saved successfully: {path}\")\n",
    "\n",
    "\n",
    "def save_csv(data, path):\n",
    "    data.to_csv(path, index=False)\n",
    "    print(f\"Files saved successfully: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved successfully: dataset/daily_counts_by_sensor.json\n"
     ]
    }
   ],
   "source": [
    "daily_counts = base_dataset.groupby([\"date\", \"name\"]).size().reset_index(name=\"count\")\n",
    "daily_counts[\"date\"] = daily_counts[\"date\"].astype(str)\n",
    "\n",
    "structured_result = {}\n",
    "\n",
    "for _, row in daily_counts.iterrows():\n",
    "    date = row[\"date\"]\n",
    "    sensor_name = row[\"name\"]\n",
    "    count = row[\"count\"]\n",
    "\n",
    "    sensor_data = base_dataset[\n",
    "        (base_dataset[\"date\"] == pd.to_datetime(date).date())\n",
    "        & (base_dataset[\"name\"] == sensor_name)\n",
    "    ]\n",
    "\n",
    "    sensor_data = sensor_data.sort_values(by=\"created_at\")\n",
    "    sensor_data[\"time_diff\"] = sensor_data[\"created_at\"].diff().dt.total_seconds()\n",
    "    average_interval = sensor_data[\"time_diff\"].mean()\n",
    "    total_energy_kWh = 0\n",
    "    for i, row in sensor_data.iterrows():\n",
    "        power = row[\"power\"]\n",
    "        interval = average_interval / 3600\n",
    "\n",
    "        energy_kWh = (power * interval) / 1000\n",
    "        total_energy_kWh += energy_kWh\n",
    "\n",
    "    if date not in structured_result:\n",
    "        structured_result[date] = {\"date\": date, \"result\": []}\n",
    "\n",
    "    structured_result[date][\"result\"].append(\n",
    "        {\n",
    "            \"name\": sensor_name,\n",
    "            \"count\": count,\n",
    "            \"interval\": average_interval,\n",
    "            \"kWh\": total_energy_kWh,\n",
    "        }\n",
    "    )\n",
    "\n",
    "final_result = list(structured_result.values())\n",
    "save_json(final_result, \"dataset/daily_counts_by_sensor.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved successfully: dataset/setup/train.json\n",
      "Files saved successfully: dataset/setup/val.json\n",
      "Files saved successfully: dataset/setup/test.json\n"
     ]
    }
   ],
   "source": [
    "final_result_df = pd.DataFrame(final_result)\n",
    "\n",
    "train_result = []\n",
    "val_result = []\n",
    "test_result = []\n",
    "\n",
    "for date_entry in final_result:\n",
    "    date = date_entry[\"date\"]\n",
    "\n",
    "    if train_date_from <= date <= train_date_to:\n",
    "        train_result.append(date_entry)\n",
    "    elif val_date_from <= date <= val_date_to:\n",
    "        val_result.append(date_entry)\n",
    "    elif test_date_from <= date <= test_date_to:\n",
    "        test_result.append(date_entry)\n",
    "\n",
    "save_json(train_result, f\"{setup_folder}/train.json\")\n",
    "save_json(val_result, f\"{setup_folder}/val.json\")\n",
    "save_json(test_result, f\"{setup_folder}/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Timestamp('2024-05-18 00:00:00'), Timestamp('2024-05-19 00:00:00'), Timestamp('2024-05-20 00:00:00'), Timestamp('2024-05-21 00:00:00'), Timestamp('2024-05-22 00:00:00'), Timestamp('2024-05-23 00:00:00'), Timestamp('2024-05-24 00:00:00'), Timestamp('2024-05-25 00:00:00'), Timestamp('2024-05-26 00:00:00'), Timestamp('2024-05-27 00:00:00'), Timestamp('2024-05-28 00:00:00'), Timestamp('2024-05-29 00:00:00'), Timestamp('2024-05-30 00:00:00'), Timestamp('2024-05-31 00:00:00'), Timestamp('2024-06-01 00:00:00'), Timestamp('2024-06-02 00:00:00'), Timestamp('2024-06-03 00:00:00'), Timestamp('2024-06-04 00:00:00'), Timestamp('2024-06-05 00:00:00'), Timestamp('2024-06-06 00:00:00'), Timestamp('2024-06-07 00:00:00'), Timestamp('2024-06-08 00:00:00'), Timestamp('2024-06-09 00:00:00'), Timestamp('2024-06-10 00:00:00'), Timestamp('2024-06-11 00:00:00'), Timestamp('2024-06-12 00:00:00'), Timestamp('2024-06-13 00:00:00'), Timestamp('2024-06-14 00:00:00'), Timestamp('2024-06-15 00:00:00'), Timestamp('2024-06-16 00:00:00'), Timestamp('2024-06-17 00:00:00'), Timestamp('2024-06-18 00:00:00'), Timestamp('2024-06-19 00:00:00'), Timestamp('2024-06-20 00:00:00'), Timestamp('2024-06-21 00:00:00'), Timestamp('2024-06-22 00:00:00'), Timestamp('2024-06-23 00:00:00'), Timestamp('2024-06-24 00:00:00'), Timestamp('2024-06-25 00:00:00'), Timestamp('2024-06-26 00:00:00'), Timestamp('2024-06-27 00:00:00'), Timestamp('2024-06-28 00:00:00'), Timestamp('2024-06-29 00:00:00'), Timestamp('2024-06-30 00:00:00')]\n",
      "[Timestamp('2024-07-01 00:00:00'), Timestamp('2024-07-02 00:00:00'), Timestamp('2024-07-03 00:00:00'), Timestamp('2024-07-04 00:00:00'), Timestamp('2024-07-05 00:00:00'), Timestamp('2024-07-06 00:00:00'), Timestamp('2024-07-07 00:00:00'), Timestamp('2024-07-08 00:00:00'), Timestamp('2024-07-09 00:00:00'), Timestamp('2024-07-10 00:00:00'), Timestamp('2024-07-11 00:00:00'), Timestamp('2024-07-12 00:00:00'), Timestamp('2024-07-13 00:00:00'), Timestamp('2024-07-14 00:00:00'), Timestamp('2024-07-15 00:00:00'), Timestamp('2024-07-16 00:00:00'), Timestamp('2024-07-17 00:00:00'), Timestamp('2024-07-18 00:00:00'), Timestamp('2024-07-19 00:00:00'), Timestamp('2024-07-20 00:00:00'), Timestamp('2024-07-21 00:00:00')]\n",
      "[Timestamp('2024-11-10 00:00:00'), Timestamp('2024-11-11 00:00:00'), Timestamp('2024-11-12 00:00:00'), Timestamp('2024-11-13 00:00:00'), Timestamp('2024-11-14 00:00:00'), Timestamp('2024-11-15 00:00:00'), Timestamp('2024-11-16 00:00:00'), Timestamp('2024-11-17 00:00:00'), Timestamp('2024-11-18 00:00:00'), Timestamp('2024-11-19 00:00:00'), Timestamp('2024-11-20 00:00:00'), Timestamp('2024-11-21 00:00:00')]\n"
     ]
    }
   ],
   "source": [
    "def get_date_ranges(json_data):\n",
    "    return [pd.to_datetime(entry[\"date\"]) for entry in json_data]\n",
    "\n",
    "\n",
    "train_dates = get_date_ranges(train_result)\n",
    "val_dates = get_date_ranges(val_result)\n",
    "test_dates = get_date_ranges(test_result)\n",
    "\n",
    "print(train_dates)\n",
    "print(val_dates)\n",
    "print(test_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sensor_data_to_csv(sensor, filter, file_type=\"train\"):\n",
    "    filtered = base_dataset[\n",
    "        (base_dataset[\"created_at\"].dt.date.isin([d.date() for d in filter]))\n",
    "        & (base_dataset[\"name\"] == sensor)\n",
    "    ]\n",
    "    file_path = os.path.join(cleaned_folder, file_type, f\"{sensor}_{file_type}.csv\")\n",
    "    save_csv(filtered, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved successfully: dataset/cleaned\\train\\Sensor 1_train.csv\n",
      "Files saved successfully: dataset/cleaned\\val\\Sensor 1_val.csv\n",
      "Files saved successfully: dataset/cleaned\\test\\Sensor 1_test.csv\n",
      "Files saved successfully: dataset/cleaned\\train\\Sensor 2_train.csv\n",
      "Files saved successfully: dataset/cleaned\\val\\Sensor 2_val.csv\n",
      "Files saved successfully: dataset/cleaned\\test\\Sensor 2_test.csv\n",
      "Files saved successfully: dataset/cleaned\\train\\Sensor 3_train.csv\n",
      "Files saved successfully: dataset/cleaned\\val\\Sensor 3_val.csv\n",
      "Files saved successfully: dataset/cleaned\\test\\Sensor 3_test.csv\n"
     ]
    }
   ],
   "source": [
    "sensors = base_dataset[\"name\"].unique()\n",
    "\n",
    "for sensor in sensors:\n",
    "    if pd.notna(sensor) and isinstance(sensor, str) and sensor.strip() != \"nan\":\n",
    "        save_sensor_data_to_csv(sensor, train_dates, \"train\")\n",
    "        save_sensor_data_to_csv(sensor, val_dates, \"val\")\n",
    "        save_sensor_data_to_csv(sensor, test_dates, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sensor_data_per_day_to_csv(sensor, date, data, folder):\n",
    "    file_name = f\"{sensor}_{date}.csv\"\n",
    "    file_path = os.path.join(folder, file_name)\n",
    "    save_csv(data, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 1_2024-11-10.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 2_2024-11-10.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 3_2024-11-10.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 1_2024-11-11.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 2_2024-11-11.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 3_2024-11-11.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 1_2024-11-12.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 2_2024-11-12.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 3_2024-11-12.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 1_2024-11-13.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 2_2024-11-13.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 3_2024-11-13.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 1_2024-11-14.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 2_2024-11-14.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 3_2024-11-14.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 1_2024-11-15.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 2_2024-11-15.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 3_2024-11-15.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 1_2024-11-16.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 2_2024-11-16.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 3_2024-11-16.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 1_2024-11-17.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 2_2024-11-17.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 3_2024-11-17.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 1_2024-11-18.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 2_2024-11-18.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 3_2024-11-18.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 1_2024-11-19.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 2_2024-11-19.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 3_2024-11-19.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 1_2024-11-20.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 2_2024-11-20.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 3_2024-11-20.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 1_2024-11-21.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 2_2024-11-21.csv\n",
      "Files saved successfully: dataset/cleaned/test_per_day\\Sensor 3_2024-11-21.csv\n"
     ]
    }
   ],
   "source": [
    "test_dates = [pd.to_datetime(date).date() for date in test_dates]\n",
    "\n",
    "for date in test_dates:\n",
    "    date_str = date.strftime(\"%Y-%m-%d\")\n",
    "    date_data = base_dataset[base_dataset[\"created_at\"].dt.date == date]\n",
    "    sensors_for_date = date_data[\"name\"].unique()\n",
    "    for sensor in sensors_for_date:\n",
    "        sensor_data = date_data[date_data[\"name\"] == sensor]\n",
    "        save_sensor_data_per_day_to_csv(\n",
    "            sensor, date_str, sensor_data, cleaned_test_per_day_folder\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
